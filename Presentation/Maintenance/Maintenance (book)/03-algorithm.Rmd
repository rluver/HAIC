# How to Detect Anomaly {#how_to_detect_anomaly}

## Traditional Approach

### Real Time Monitoring

```{r echo = F}
knitr::include_graphics('./images/Chapter_02/monitoring.png')
```

### Fast Fourier Transforms (FFT)

```{r echo = F}
knitr::include_graphics('./images/Chapter_02/fft.jpg')
```

### Orbit Analysis

```{r echo = F}
knitr::include_graphics('./images/Chapter_02/orbit.jpg')
```


## Deep Learning Approach

### Deep Learning

#### What is Deep Learning?

```{r echo = F, fig.cap = 'Difference between ML and DL', fig.align = 'center'}
knitr::include_graphics('./images/Chapter_03/mldl.png')
```
```{r echo = F, out.width = 700, fig.cap = 'Deep Learning Architecture', fig.align = 'center'}
knitr::include_graphics('./images/Chapter_03/dl.png')
```

여러 비선형 변환기법의 조합을 통해 높은 수준의 추상화를 시도하는 기계 학습 알고리즘의 집합 으로 정의되며, 큰 틀에서 사람의 사고방식을 컴퓨터에게 가르치는 기계학습의 한 분야라고 이야기할 수 있다.

#### What is CNN?

```{r echo = F, out.width = 700, fig.cap = 'Deep Learning Architecture', fig.align = 'center'}
knitr::include_graphics('./images/Chapter_03/cnn.jpeg')
```

합성곱 신경망(Convolutional Neural Network, CNN)은 시각적 이미지를 분석하는 데 사용되는 깊고 피드-포워드적인 인공신경망의 한 종류이다. 딥 러닝에서 심층 신경망으로 분류되며, 시각적 이미지 분석에 가장 일반적으로 적용된다. 또한 공유 가중치 구조와 변환 불변성 특성에 기초하여 변이 불변 또는 공간 불변 인공 신경망 (SIANN)으로도 알려져 있다. 이미지 및 비디오 인식, 추천 시스템, 이미지 분류, 의료 이미지 분석 및 자연어 처리에 응용된다. <br>

CNN은 정규화 된 버전의 다층 퍼셉트론이다. 다층 퍼셉트론은 일반적으로 완전히 연결된 네트워크, 즉 한 계층의 각 뉴런이 다음 계층의 모든 뉴런에 연결됨을 의미한다. 이러한 네트워크의 "완전히 연결"은 주어진 데이터에 과적합 되는 경향이 있다. 일반적인 정규화 방법에는 손실 함수에 몇 가지 형태의 가중치 측정을 추가하는 것이 포함되지만, CNN은 정규화를 향한 다른 접근 방식을 취한다. 데이터에서 계층적 패턴을 활용하고 더 작고 간단한 패턴을 사용하여 더 복잡한 패턴을 조립한다. 따라서 연결성과 복잡성의 규모에서 CNN은 극단적으로 낮다. <p>

컨볼 루션 네트워크는 뉴런 사이의 연결 패턴이 동물 시각 피질의 조직과 유사하다는 생물학적 과정에 의해 영감을 받았다. 개별 피질 뉴런은 수용장으로 알려진 시야의 제한된 영역에서만 자극에 반응한다. 상이한 뉴런의 수용 필드는 전체 시야를 커버하도록 부분적으로 중첩된다. <p>

CNN은 다른 이미지 분류 알고리즘에 비해 상대적으로 전처리를 거의 사용하지 않는다. 이는 네트워크가 기존 알고리즘에서 수작업으로 제작된 필터를 학습한다는 것을 의미한다. 피처 디자인에 대한 사전 지식과 인간 노력과의 독립성은 CNN의 주요한 장점다. <p>

#### What is RNN?

```{r echo = F, out.width = 700, fig.cap = 'RNN Architecture', fig.align = 'center'}
knitr::include_graphics('./images/Chapter_03/rnn.png')
```

순환 인공 신경망(Recurrent Neural Network, RNN)은 인공 신경망의 한 종류로, 유닛간의 연결이 순환적 구조를 갖는 특징을 갖고 있다. 이러한 구조는 시변적 동적 특징을 모델링 할 수 있도록 신경망 내부에 상태를 저장할 수 있게 해준다. 전방 전달 신경망과 달리, 순환 인공 신경망은 내부의 메모리를 이용해시퀀스 형태의 입력을 처리할 수 있다. 따라서 순환 인공 신경망은 필기체 인식이나 음성 인식과 같이 시변적 특징을 가지는 데이터를 처리할 수 있다. RNN은 블록의 처리 방식에 따라 크게 다음 3가지로 구분한다. 

##### RNN (Recurrent Neural Networks)

```{r echo = F, out.width = 700, fig.cap = 'RNN Cell', fig.align = 'center'}
knitr::include_graphics('./images/Chapter_03/rnn_cell.png')
```

<h4> Notation </h4>
$x_{t}$ : input vector ($m$ x 1). <br>
$h_{t}$ : hidden layer vector ($n$ x 1). <br>
$o_{t}$ : output vector ($n$ x 1). <br>
$b_{h}$ : bias vector ($n$ x 1). <br>
$U,W$ : parameter matrices ($n$ x $m$). <br>
$V$ : parameter matrix ($n$ x $n$). <br>
$\sigma_{h}, \sigma_{y}$ : activation functions. <br>

<h4> Feedforward </h4>

```{r echo = F, out.width = 700, fig.cap = 'RNN Feedforward', fig.align = 'center'}
knitr::include_graphics('./images/Chapter_03/rnn_feedforward.png')
```
\[ h_t=\sigma_h(i_t)=\sigma_h(U_hx_t+V_hh_{t-1}+b_h) \]
\[ y_t=\sigma_y(a_t)=\sigma_y(W_yh_t+b_h) \]
  
<h4> Backpropagation </h4>

```{r echo = F, out.width = 700, fig.cap = 'RNN Backpropagation', fig.align = 'center'}
knitr::include_graphics('./images/Chapter_03/rnn_backpropagation.png')
```

```{r echo = F, out.width = 700, fig.cap = 'RNN Backpropagation 2', fig.align = 'center'}
knitr::include_graphics('./images/Chapter_03/rnn_backpropagation2.png')
```

\[ \Pi_t= \frac{\partial E_t}{\partial o_t} \frac{\partial o_t}{\partial h_t}+ \frac{\partial h_{t+1}}{\partial h_t} \Pi_{t+1} \]
\[ \beta_t^U=\beta_{t+1}^U+\Pi_t \frac{\partial h_t}{\partial U_t} \]
\[ \beta_t^V=\beta_{t+1}^V+\Pi_t \frac{\partial h_t}{\partial V_t} \]
\[ \beta_t^W=\beta_{t+1}^W+ \frac{\partial E_t}{\partial o_t} \frac{\partial o_t}{\partial W_t} \]
\[ \frac{\partial E}{\partial X} \equiv \beta_0^x \] <br>

<h4> Problem </h4>

<h5> 1. BPTT(BackPropagation Through Time)

```{r echo = F, out.width = 700, fig.cap = 'RNN BPTT Problem', fig.align = 'center'}
knitr::include_graphics('./images/Chapter_03/rnn_bptt_problem.png')
```

RNN에서의 역전파 방법인 BPTT는 아래의 그림과 같이 모든 스텝마다 처음부터 끝까지 역전파한다. 그렇기 때문에 망이 깊어질 때, 그래디언트 소실 및 폭주(vanishing & exploding gradient) 문제가 발생할 가능성이 크다. 또한, 계산량이 많아 한 번 학습하는 데 시간이 오래 걸리는 문제가 있다.

```{r echo = F, out.width = 700, fig.cap = 'RNN Truncated BPTT', fig.align = 'center'}
knitr::include_graphics('./images/Chapter_03/rnn_truncated_bptt.png')
```

BPTT의 이러한 문제를 해결하기 위해 아래의 그림과 같이 타임 스텝을 일정 구간으로 나누어 역전파를 수행하여, 전체 역전파로 근사시키는 방법인 Truncated BPTT를 대안으로 사용할 수 있다. 하지만 Truncated BPTT는 만약 학습 데이터가 장기간에 걸쳐 패턴이 발생한다고 하면, 이러한 장기간(Long-Term)의 패턴을 학습할 수 없는 문제가 있다.

<h5> 2. 장기 의존성(Long-Term Dependency) 문제

```{r echo = F, out.width = 700, fig.cap = 'RNN Long_Term Dependency Problem', fig.align = 'center'}
knitr::include_graphics('./images/Chapter_03/rnn_long_term_dependency.png')
```

RNN은 타임 스텝 $t$ 에서 이전 타임 스텝($t-1$)의 상태(state, $h_{t-1}$)를 입력으로 받는 구조이기 때문에, 이전의 정보가 현재의 타임 스텝 $t$에 영향을 줄 수 있다. 이렇듯, RNN은 이론적으로 모든 이전 타임 스텝이 영향을 주지만 앞쪽의 타임 스텝(예를 들어 $t = 0, t = 1$ )은 타임 스텝이 길어질 수록 영향을 주지 못하는 문제가 발생하는데 이를 장기 의존성(Long-Term Dependency) 문제라고 한다. 이러한 문제가 발생하는 이유는 입력 데이터가 RNN Cell을 거치면서 특정 연산을 통해 데이터가 변환되어, 일부 정보는 타임 스텝마다 사라지기 때문이다. <br>

이러한 문제를 해결하기 위해 장기간의 메모리를 가질 수 있는 여러 종류의 셀이 만들어졌는데, 그 중에서 대표적인 셀들이 LSTM과 GRU 셀이다. 먼저, LSTM 셀에 대해 알아보도록 하자.

##### LSTM (Long Short-Term Memory)

```{r echo = F, out.width = 700, fig.cap = 'LSTM Cell', fig.align = 'center'}
knitr::include_graphics('./images/Chapter_03/lstm_cell.png')
```

<h4> Notation </h4>
$h_t, C_t$ : hidden layer vectors. <br>
$x_t$ : input vector. <br>
$b_f, b_i, b_c , b_o$ : bias vector. <br>
$W_f , W_i , W_c , W_o$ : parameter matrices. <br>
$\sigma , \tanh$ : activation functions. <br>

아래에서는 간단하게 셀의 구조를 알아보도록 한다.


```{r echo = F, out.width = 700, fig.cap = 'LSTM Cell State', fig.align = 'center'}
knitr::include_graphics('./images/Chapter_03/lstm_cell_state.png')
```

먼저 맨 위를 가로지르는 선 C를 cell state라고 부른다.

일반적인 RNN에서는 곱하기 연산으로만 이루어져 있었는데 LSTM에서는 피드백을 더하기(+)로 이음으로써 기울기 소실(Vanishing Gradient)과 같은 문제를 해결할 수 있다.

cell state 또한 이전에 배운 은닉 상태처럼 이전 시점의 cell state가 다음 시점의 cell state를 구하기 위한 입력으로서 사용된다.

LSTM은 이 cell state를 보호하고 컨트롤 하기 위한 세 가지 게이트: forget, input, output gate를 통해 vanishing gradient를 방지하고 그래디언트가 효과적으로 흐를 수 있게 한다.

```{r echo = F, out.width = 700, fig.cap = 'LSTM Forget Gate', fig.align = 'center'}
knitr::include_graphics('./images/Chapter_03/lstm_forget_gate.png')
```

LSTM의 첫번째 단계는 정보를 얼마나 잊을지에 관한 단계이다.

이전상태의 hidden state(h)와 현재 상태의 input(x)이 시그모이드 함수를 거치면 0~1의 값이 나오게 된다.

이는 삭제 과정을 거친 정보의 양인데, 0에 가까울수록 정보가 많이 삭제된 것이고 1에 가까울수록 정보를 온전히 기억하게 된다.
해당 값은 다다음 단계에서의 cell state update에서 cell state(C)에 적용되게 됩니다.

```{r echo = F, out.width = 700, fig.cap = 'LSTM Input Gate', fig.align = 'center'}
knitr::include_graphics('./images/Chapter_03/lstm_input_gate.png')
```

그 다음 Gate에서는 현재 상태의 input(x)를 얼마나 기억할 것인지에 대한 것을 계산한다.

이전상태의 hidden state(h)와 현재상태의 input(x)값을 시그모이드와 하이퍼볼릭탄젠트(tanh)로 지나게 한다.
이렇게 하면 시그모이드를 지난 값은 0에서 1의 값을 가지며 gate의 역할을 하게 되고(input gate),
tanh를 지난 값은 -1에서 1의 값을 가지며 현재 cell state를 나타내게 됩니다.

활성화함수가 tanh인 것을 제외하면 기존 RNN에서의 hidden state를 구하는 공식과 같은 것을 확인할 수 있다.

```{r echo = F, out.width = 700, fig.cap = 'LSTM State Update', fig.align = 'center'}
knitr::include_graphics('./images/Chapter_03/lstm_state_update.png')
```

이제는 1단계에서의 forget gate의 값, 2단계에서의 현재 cell state 값, input gate 값을 업데이트 해줘야 한다.

1. 이전단계의 cell state에 forget gate(얼마나 잊을건지)를 Hadamard product계산(각 행렬의 인자끼리 곱하기)
2. 현재 cell state에 input gate(얼마나 반영할지)를 Hadamard product계산
2번의 결과를 1번의 결과와 더함
3. 최종 결과를 다음 상태의 cell state로 보낸다

만약 forget gate와 input gate 둘다 0이라면 이전단계의 cell state가 그대로 다음상태로 넘어가고, 둘다 1이면 이전단계의 cell state는 전부 잊혀지고 현재 상태의 cell state가 그대로 다음 상태로 넘어가게 된다.

```{r echo = F, out.width = 700, fig.cap = 'LSTM Output Gate', fig.align = 'center'}
knitr::include_graphics('./images/Chapter_03/lstm_output_gate.png')
```

cell state의 계산은 끝났으니 이제 다음 상태로 보낼 (output)hidden state를 구해야 한다.

3단계까지 이뤄진 cell state를 tanh취해준 후 output gate를 통해 얼마나 다음단계로 보낼 건지를 계산한다.

<h4> Feed Forward </h4>

```{r echo = F, out.width = 700, fig.cap = 'LSTM Feedforward', fig.align = 'center'}
knitr::include_graphics('./images/Chapter_03/lstm_feedforward.png')
```

```{r echo = F, out.width = 700, fig.cap = 'LSTM Feedforward 2', fig.align = 'center'}
knitr::include_graphics('./images/Chapter_03/lstm_feedforward2.png')
```

\[ f_t=\sigma(W_f\cdot[h_{t-1},x_t]+b_f) \]
\[ i_t=\sigma(W_i\cdot[h_{t-1},x_t]+b_i) \]
\[ o_t=\sigma(W_o\cdot[h_{t-1},x_t]+b_o) \]
\[ \tilde{C}_t=\tanh(W_c\cdot[h_{t-1},x_t]+b_c) \]
\[ C_t=f_t\odot C_{t-1}+i_t\odot\tilde{C}_t \]
\[ h_t=o_t\odot\tanh(C_t) \]

<h4> Backpropagation </h4>

```{r echo = F, out.width = 700, fig.cap = 'LSTM Backpropagation', fig.align = 'center'}
knitr::include_graphics('./images/Chapter_03/lstm_backpropagation.png')
```

```{r echo = F, out.width = 700, fig.cap = 'LSTM Backpropagation 2', fig.align = 'center'}
knitr::include_graphics('./images/Chapter_03/lstm_backpropagation2.png')
```

```{r echo = F, out.width = 700, fig.cap = 'LSTM Backpropagation 3', fig.align = 'center'}
knitr::include_graphics('./images/Chapter_03/lstm_backpropagation3.png')
```

\begin{align*} &\frac{\partial C_{t+1}}{\partial h_t}= \frac{\partial C_{t+1}}{\partial \tilde{C}_{t+1}} \frac{\partial \tilde{C}_{t+1}}{\partial h_t}+ \frac{\partial C_{t+1}}{\partial f_{t+1}} \frac{\partial f_{t+1}}{\partial h_t}+ \frac{\partial C_{t+1}}{\partial t_{t+1}} \frac{\partial i_{t+1}}{\partial h_t}\\ &\frac{\partial C_{t+1}}{\partial C_t}\\ &\frac{\partial h_{t+1}}{\partial C_t}= \frac{\partial h_{t+1}}{\partial C_{t+1}} \frac{\partial C_{t+1}}{\partial C_t}\\ &\frac{\partial h_{t+1}}{\partial h_t}= \frac{\partial h_{t+1}}{\partial C_{t+1}} \frac{\partial C_{t+1}}{\partial h_t}+ \frac{\partial h_{t+1}}{\partial o_{t+1}} \frac{\partial o_{t+1}}{\partial h_t} \end{align*}
\[ \Pi_t= \frac{\partial E_t}{\partial h_t}+ \frac{\partial h_{t+1}}{\partial h_t} \Pi_{t+1}+ \frac{\partial C_{t+1}}{\partial h_t} \mathcal{T}_{t+1} \]
\[ \mathcal{T}_t= \frac{\partial E_t}{\partial h_t} \frac{\partial E_t}{\partial C_t}+ \frac{\partial h_{t+1}}{\partial C_t} \Pi_{t+1}+ \frac{\partial C_{t+1}}{\partial C_t} \mathcal{T}_{t+1} \]
\[ \beta_t^f=\beta_{t+1}^f+ \frac{\partial C_t}{\partial f_t} \frac{\partial f_t}{\partial W_t^f} ( \frac{\partial h_t}{\partial C_t} \Pi_t + \mathcal{T}_t ) \]
\[ \beta_t^i=\beta_{t+1}^i+ \frac{\partial C_t}{\partial i_t} \frac{\partial i_t}{\partial W_t^i} ( \frac{\partial h_t}{\partial C_t} \Pi_t + \mathcal{T}_t ) \]
\[ \beta_t^c=\beta_{t+1}^c+ \frac{\partial C_t}{\partial \tilde{C}_{t}} \frac{\partial \tilde{C}_{t}}{\partial W_t^c} ( \frac{\partial h_t}{\partial C_t} \Pi_t + \mathcal{T}_t ) \]
\[ \beta_t^o=\beta_{t+1}^o+ \frac{\partial h_t}{\partial o_t} \frac{\partial o_t}{\partial W_t^o} ( \Pi_t ) \]

##### GRU (Gated Recurrent Unit)

```{r echo = F, out.width = 700, fig.cap = 'GRU Cell', fig.align = 'center'}
knitr::include_graphics('./images/Chapter_03/gru_cell.png')
```

<h4> Notation </h4>
$h_t$ : hidden layer vectors. <br>
$x_t$ : input vector. <br>
$b_z , b_r , b_h$ : bias vector. <br>
$W_z , W_r , W_h$ : parameter matrices. <br>
$\sigma , \tanh$ : activation functions. <br>

<h4> Feed Forward </h4>
\[ z_t=\sigma(W_z \cdot[h_{t-1},x_t]+b_z) \]
\[ r_t=\sigma(W_r \cdot [h_{t-1},x_t]+b_r) \]
\[ \tilde{h}_t=\tanh(W_h\cdot[r_t \odot h_{t-1},x_t]+b_h) \]
\[ h_t=(1-z_t)\odot h_{t-1}+z_t\odot \tilde{h}_t \]

<h4> Backpropagation </h4>
\[ \frac{\partial h_{t+1}}{\partial h_t}= \frac{\partial h_{t+1}}{\partial h_t}+ \frac{\partial h_{t+1}}{\partial z_{t+1}} \frac{\partial z_{t+1}}{\partial h_t}+ \frac{\partial h_{t+1}}{\partial \tilde{h}_{t+1}} ( \frac{\partial \tilde{h}_{t+1}}{\partial h_t}+ \frac{\partial \tilde{h}_{t+1}}{\partial r_{t+1}} \frac{\partial r_{t+1}}{\partial h_t} ) \]
\[ \Pi_t= \frac{\partial E_t}{\partial h_t}+ \frac{\partial h_{t+1}}{\partial h_t} \Pi_{t+1} \]
\[ \beta_t^z=\beta_{t+1}^z+ \frac{\partial h_t}{\partial z_t} \frac{\partial z_t}{\partial W_t^z} \Pi_t \]
\[ \beta_t^r=\beta_{t+1}^r+ \frac{\partial h_t}{\partial \tilde{h}_t} \frac{\partial \tilde{h}_t}{\partial r_t} \frac{\partial r_t}{\partial W_t^r} \Pi_t \]
\[ \beta_t^h=\beta_{t+1}^h+ \frac{\partial h_t}{\partial \tilde{h}_t} \frac{\partial \tilde{h}_t}{\partial W_t^h} \Pi_t \]

#### What is CRNN?

```{r echo = F, out.width = 700, fig.cap = 'CRNN Architecture', fig.align = 'center', fig.cap = ''}
knitr::include_graphics('./images/Chapter_03/crnn.png')
```

```{r, echo = F, out.width = 700, fig.cap = 'Feature Sequence', fig.align = 'center', fig.subcap = 'An End-to-End Trainable Neural Network for Image-based Sequence Recognition and Its Application to Scene Text Recognition'}
knitr::include_graphics('./images/Chapter_03/feature_sequence.png')
```

### Applications
